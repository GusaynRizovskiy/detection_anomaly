# -*- coding: utf-8 -*-
import os
import sys
import pandas as pd
import numpy as np
from PyQt5 import QtCore
import logging
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, LSTM, RepeatVector
from sklearn.preprocessing import MinMaxScaler
import pickle
from tensorflow.keras.callbacks import Callback

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—á–µ–≥–æ –ø–æ—Ç–æ–∫–∞
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class PlotCallback(Callback):
    """
    –ö–ª–∞—Å—Å –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ loss –Ω–∞ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–µ.
    """

    def __init__(self, signal):
        super().__init__()
        self.signal = signal

    def on_epoch_end(self, epoch, logs=None):
        loss = logs.get('loss')
        val_loss = logs.get('val_loss')
        if loss is not None and val_loss is not None:
            self.signal.emit({'epoch': epoch, 'loss': loss, 'val_loss': val_loss})


class Worker(QtCore.QObject):
    """
    –ö–ª–∞—Å—Å-—Ä–∞–±–æ—Ç–Ω–∏–∫ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–µ–º–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ.
    –ù–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç QObject –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤.
    """

    learning_finished = QtCore.pyqtSignal(dict)
    testing_finished = QtCore.pyqtSignal(dict)
    update_status_signal = QtCore.pyqtSignal(str)
    # –ù–û–í–´–ô –°–ò–ì–ù–ê–õ: –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
    update_plot_signal = QtCore.pyqtSignal(dict)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.autoencoder = None
        self.scaler = None
        self.is_learning_running = False
        self.is_testing_running = False
        self.epoch_data = {'loss': [], 'val_loss': []}

    def load_and_preprocess_data(self, file_path, scaler, fit_scaler=True):
        """–ó–∞–≥—Ä—É–∑–∫–∞, –æ—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π."""
        if not file_path:
            raise ValueError("–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –Ω–µ —É–∫–∞–∑–∞–Ω.")

        data = None
        delimiters = [';', ',', '\t']

        # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        for delimiter in delimiters:
            try:
                data = pd.read_csv(file_path, delimiter=delimiter, encoding='utf-8')
                if data.shape[1] > 1:
                    self.update_status_signal.emit(
                        f"‚úÖ –§–∞–π–ª '{os.path.basename(file_path)}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{delimiter}'.")
                    break
                else:
                    self.update_status_signal.emit(
                        f"‚ö†Ô∏è –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω, –Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å—Ç–æ–ª–±–µ—Ü —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{delimiter}'. –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å...")
                    data = None
            except Exception:
                try:  # –ü—Ä–æ–±—É–µ–º cp1251
                    data = pd.read_csv(file_path, delimiter=delimiter, encoding='cp1251')
                    if data.shape[1] > 1:
                        self.update_status_signal.emit(
                            f"‚úÖ –§–∞–π–ª '{os.path.basename(file_path)}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{delimiter}' –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π cp1251.")
                        break
                    else:
                        data = None
                except Exception:
                    self.update_status_signal.emit(
                        f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{delimiter}'. –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π...")
                    data = None

        if data is None or data.shape[1] <= 1:
            raise ValueError(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª, —Ç–∞–∫ –∫–∞–∫ –Ω–∏ –æ–¥–∏–Ω –∏–∑ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã—Ö —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π (';', ',', '\\t') –Ω–µ –ø–æ–¥–æ—à–µ–ª –∏–ª–∏ —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å—Ç–æ–ª–±–µ—Ü.")

        data.columns = data.columns.str.strip()
        self.update_status_signal.emit(f"üìù –°—Ç–æ–ª–±—Ü—ã –≤ —Ñ–∞–π–ª–µ: {', '.join(data.columns)}")

        if data.empty:
            raise ValueError("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π CSV-—Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö.")

        if '–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤' in data.columns:
            data.drop(columns=['–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤'], inplace=True)
            self.update_status_signal.emit("üóëÔ∏è –°—Ç–æ–ª–±–µ—Ü '–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤' —É–¥–∞–ª–µ–Ω.")

        data = data.replace(',', '.', regex=True)
        data = data.apply(pd.to_numeric, errors='coerce')
        self.update_status_signal.emit(f"üî¢ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ {data.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç.")

        rows_before = len(data)
        data = data.dropna()
        rows_after = len(data)
        if rows_before - rows_after > 0:
            self.update_status_signal.emit(f"‚ùå –£–¥–∞–ª–µ–Ω–æ {rows_before - rows_after} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.")

        if data.empty:
            raise ValueError("–í DataFrame –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª–µ.")

        if fit_scaler or scaler is None:
            new_scaler = MinMaxScaler()
            scaled_data = new_scaler.fit_transform(data)
            self.update_status_signal.emit("üìä –î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã –Ω–æ–≤—ã–º MinMaxScaler.")
            return scaled_data, new_scaler
        else:
            scaled_data = scaler.transform(data)
            self.update_status_signal.emit("üìä –î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º MinMaxScaler.")
            return scaled_data, scaler

    def create_dataset(self, data, time_step):
        X = []
        for i in range(len(data) - time_step):
            a = data[i:(i + time_step), :]
            X.append(a)
        return np.array(X)

    def build_cnn_lstm_autoencoder(self, input_shape):
        input_layer = Input(shape=input_shape)
        conv_encoder = Conv1D(32, kernel_size=3, activation='relu', padding='same')(input_layer)
        lstm_encoder = LSTM(50, activation='relu', return_sequences=False)(conv_encoder)
        repeat = RepeatVector(input_shape[0])(lstm_encoder)
        lstm_decoder = LSTM(50, activation='relu', return_sequences=True)(repeat)
        conv_decoder = Conv1D(32, kernel_size=3, activation='relu', padding='same')(lstm_decoder)
        output_layer = Conv1D(input_shape[1], kernel_size=3, padding='same')(conv_decoder)
        model = Model(inputs=input_layer, outputs=output_layer)
        model.compile(optimizer='adam', loss='mse')
        return model

    @QtCore.pyqtSlot(str, int, int, int)
    def start_learning(self, file_path, time_step, epochs, batch_size):
        if self.is_learning_running:
            self.update_status_signal.emit("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            return

        self.is_learning_running = True
        self.update_status_signal.emit("‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        self.epoch_data = {'loss': [], 'val_loss': []}

        try:
            scaled_data, self.scaler = self.load_and_preprocess_data(file_path, self.scaler, fit_scaler=True)
            X_train = self.create_dataset(scaled_data, time_step)

            if X_train.size == 0:
                raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω. –£–º–µ–Ω—å—à–∏—Ç–µ '–í—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥'.")

            X_train = X_train.reshape(X_train.shape[0], time_step, scaled_data.shape[1])
            self.autoencoder = self.build_cnn_lstm_autoencoder((X_train.shape[1], X_train.shape[2]))

            plot_callback = PlotCallback(self.update_plot_signal)

            history = self.autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, validation_split=0.2,
                                           verbose=0, callbacks=[plot_callback])

            self.update_status_signal.emit("üß† –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞. –†–∞—Å—á–µ—Ç –ø–æ—Ä–æ–≥–∞ –∞–Ω–æ–º–∞–ª–∏–π...")

            reconstruction_errors = np.mean(np.power(X_train - self.autoencoder.predict(X_train, verbose=0), 2),
                                            axis=(1, 2))
            threshold = np.percentile(reconstruction_errors, 95)

            results = {
                'loss': history.history['loss'],
                'val_loss': history.history['val_loss'],
                'threshold': threshold
            }

            self.learning_finished.emit(results)
            self.update_status_signal.emit("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        except Exception as e:
            self.update_status_signal.emit(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}")
            logging.error("–û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—á–µ–º –ø–æ—Ç–æ–∫–µ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è", exc_info=True)
        finally:
            self.is_learning_running = False

    @QtCore.pyqtSlot(str, int, float)
    def start_testing(self, file_path, time_step, threshold):
        if self.is_testing_running:
            self.update_status_signal.emit("‚ö†Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            return
        if self.autoencoder is None or self.scaler is None:
            self.update_status_signal.emit("‚ö†Ô∏è –û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            return

        self.is_testing_running = True
        self.update_status_signal.emit("‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        try:
            scaled_data, _ = self.load_and_preprocess_data(file_path, self.scaler, fit_scaler=False)
            X_new = self.create_dataset(scaled_data, time_step)

            if X_new.size == 0:
                raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω. –£–º–µ–Ω—å—à–∏—Ç–µ '–í—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥'.")

            X_new = X_new.reshape(X_new.shape[0], time_step, scaled_data.shape[1])

            self.update_status_signal.emit("üîç –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            reconstruction_errors = np.mean(np.power(X_new - self.autoencoder.predict(X_new, verbose=0), 2),
                                            axis=(1, 2))
            anomalies = np.where(reconstruction_errors > threshold)[0]

            results = {
                'reconstruction_errors': reconstruction_errors,
                'anomalies': anomalies
            }

            self.testing_finished.emit(results)
            self.update_status_signal.emit(f"‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π.")
        except Exception as e:
            self.update_status_signal.emit(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            logging.error("–û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—á–µ–º –ø–æ—Ç–æ–∫–µ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", exc_info=True)
        finally:
            self.is_testing_running = False

    def stop(self):
        pass