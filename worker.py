# -*- coding: utf-8 -*-
import os
import sys
import pandas as pd
import numpy as np
from PyQt5 import QtCore
import logging
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, LSTM, RepeatVector
from sklearn.preprocessing import MinMaxScaler
import pickle
from tensorflow.keras.callbacks import Callback
import socket
import json
import collections
from datetime import datetime

logger = logging.getLogger(__name__)


# –ö–ª–∞—Å—Å –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –æ–±—É—á–µ–Ω–∏—è
class PlotCallback(Callback):
    """
    –ö–ª–∞—Å—Å –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ loss –Ω–∞ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–µ.
    """

    def __init__(self, signal):
        super().__init__()
        self.signal = signal

    def on_epoch_end(self, epoch, logs=None):
        loss = logs.get('loss')
        val_loss = logs.get('val_loss')
        if loss is not None and val_loss is not None:
            self.signal.emit({'epoch': epoch, 'loss': loss, 'val_loss': val_loss})


# --- –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–¥–∞—á –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è ---
class MLWorker(QtCore.QObject):
    """
    –ö–ª–∞—Å—Å-—Ä–∞–±–æ—Ç–Ω–∏–∫ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–µ–º–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π ML –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ.
    """
    learning_finished = QtCore.pyqtSignal(dict)
    testing_finished = QtCore.pyqtSignal(dict)
    online_results_signal = QtCore.pyqtSignal(dict)
    update_status_signal = QtCore.pyqtSignal(str)
    update_plot_signal = QtCore.pyqtSignal(dict)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.autoencoder = None
        self.scaler = None
        self.is_learning_running = False
        self.is_testing_running = False

    def load_and_preprocess_data(self, file_path, scaler, fit_scaler=True):
        """–ó–∞–≥—Ä—É–∑–∫–∞, –æ—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π."""
        if not file_path:
            logger.error("–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –Ω–µ —É–∫–∞–∑–∞–Ω.")
            raise ValueError("–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –Ω–µ —É–∫–∞–∑–∞–Ω.")

        data = None
        delimiters = [';', ',', '\t']
        encodings = ['utf-8', 'cp1251']

        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞: {file_path}")
        for delimiter in delimiters:
            for encoding in encodings:
                try:
                    data = pd.read_csv(file_path, delimiter=delimiter, encoding=encoding)
                    if data.shape[1] > 1:
                        self.update_status_signal.emit(
                            f"‚úÖ –§–∞–π–ª '{os.path.basename(file_path)}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{delimiter}' –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π '{encoding}'.")
                        logger.info(f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω. –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: {delimiter}, –ö–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding}")
                        break
                except Exception as e:
                    logger.warning(
                        f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{delimiter}' –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π '{encoding}': {e}")
                    data = None
            if data is not None and data.shape[1] > 1:
                break

        if data is None or data.shape[1] <= 1:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –∏–ª–∏ –æ–Ω –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç–æ–ª–±—Ü–æ–≤.")
            raise ValueError(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª CSV –Ω–µ –ø—É—Å—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª–µ–µ –æ–¥–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ (';', ',', '\\t').")

        data.columns = data.columns.str.strip()
        self.update_status_signal.emit(f"üìù –°—Ç–æ–ª–±—Ü—ã –≤ —Ñ–∞–π–ª–µ: {', '.join(data.columns)}")

        if data.empty:
            logger.error("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π CSV-—Ñ–∞–π–ª –ø—É—Å—Ç –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏.")
            raise ValueError("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π CSV-—Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö.")

        if '–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤' in data.columns:
            data.drop(columns=['–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤'], inplace=True)
            self.update_status_signal.emit("üóëÔ∏è –°—Ç–æ–ª–±–µ—Ü '–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤' —É–¥–∞–ª–µ–Ω.")

        data = data.replace(',', '.', regex=True)
        data = data.apply(pd.to_numeric, errors='coerce')
        self.update_status_signal.emit(f"üî¢ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ {data.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç.")

        rows_before = len(data)
        data = data.dropna()
        rows_after = len(data)
        if rows_before - rows_after > 0:
            self.update_status_signal.emit(f"‚ùå –£–¥–∞–ª–µ–Ω–æ {rows_before - rows_after} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.")
            logger.warning(f"–£–¥–∞–ª–µ–Ω–æ {rows_before - rows_after} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.")

        if data.empty:
            logger.error("–í DataFrame –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.")
            raise ValueError("–í DataFrame –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª–µ.")

        if fit_scaler or scaler is None:
            new_scaler = MinMaxScaler()
            scaled_data = new_scaler.fit_transform(data)
            self.update_status_signal.emit("üìä –î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã –Ω–æ–≤—ã–º MinMaxScaler.")
            logger.info("–î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã –Ω–æ–≤—ã–º MinMaxScaler.")
            return scaled_data, new_scaler
        else:
            scaled_data = scaler.transform(data)
            self.update_status_signal.emit("üìä –î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º MinMaxScaler.")
            logger.info("–î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º MinMaxScaler.")
            return scaled_data, scaler

    def create_dataset(self, data, time_step):
        X = []
        for i in range(len(data) - time_step):
            a = data[i:(i + time_step), :]
            X.append(a)
        return np.array(X)

    def build_cnn_lstm_autoencoder(self, input_shape):
        input_layer = Input(shape=input_shape)
        conv_encoder = Conv1D(32, kernel_size=3, activation='relu', padding='same')(input_layer)
        lstm_encoder = LSTM(50, activation='relu', return_sequences=False)(conv_encoder)
        repeat = RepeatVector(input_shape[0])(lstm_encoder)
        lstm_decoder = LSTM(50, activation='relu', return_sequences=True)(repeat)
        conv_decoder = Conv1D(32, kernel_size=3, activation='relu', padding='same')(lstm_decoder)
        output_layer = Conv1D(input_shape[1], kernel_size=3, padding='same')(conv_decoder)
        model = Model(inputs=input_layer, outputs=output_layer)
        model.compile(optimizer='adam', loss='mse')
        return model

    @QtCore.pyqtSlot(str, int, int, int)
    def start_learning(self, file_path, time_step, epochs, batch_size):
        if self.is_learning_running:
            self.update_status_signal.emit("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è.")
            return

        self.is_learning_running = True
        self.update_status_signal.emit("‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        logger.info(
            f"–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è. –§–∞–π–ª: {file_path}, –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥: {time_step}, —ç–ø–æ—Ö–∏: {epochs}, –±–∞—Ç—á: {batch_size}")

        try:
            scaled_data, self.scaler = self.load_and_preprocess_data(file_path, self.scaler, fit_scaler=True)
            X_train = self.create_dataset(scaled_data, time_step)

            logger.info(f"–°–æ–∑–¥–∞–Ω–æ {X_train.shape[0]} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")

            if X_train.size == 0:
                raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω. –£–º–µ–Ω—å—à–∏—Ç–µ '–í—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥'.")

            X_train = X_train.reshape(X_train.shape[0], time_step, scaled_data.shape[1])
            self.autoencoder = self.build_cnn_lstm_autoencoder((X_train.shape[1], X_train.shape[2]))

            plot_callback = PlotCallback(self.update_plot_signal)

            history = self.autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, validation_split=0.2,
                                           verbose=0, callbacks=[plot_callback])
            logger.info("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")

            self.update_status_signal.emit("üß† –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞. –†–∞—Å—á–µ—Ç –ø–æ—Ä–æ–≥–∞ –∞–Ω–æ–º–∞–ª–∏–π...")

            reconstruction_errors = np.mean(np.power(X_train - self.autoencoder.predict(X_train, verbose=0), 2),
                                            axis=(1, 2))
            threshold = np.percentile(reconstruction_errors, 95)
            logger.info(f"–†–∞—Å—Å—á–∏—Ç–∞–Ω –ø–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª–∏–π: {threshold:.4f}")

            results = {
                'threshold': threshold
            }

            self.learning_finished.emit(results)
            self.update_status_signal.emit("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        except Exception as e:
            self.update_status_signal.emit(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}")
            logger.error("–û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—á–µ–º –ø–æ—Ç–æ–∫–µ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è", exc_info=True)
        finally:
            self.is_learning_running = False

    @QtCore.pyqtSlot(str, int, float)
    def start_testing(self, file_path, time_step, threshold):
        if self.is_testing_running:
            self.update_status_signal.emit("‚ö†Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
            return
        if self.autoencoder is None or self.scaler is None:
            self.update_status_signal.emit("‚ö†Ô∏è –û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            logger.error("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ: –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            return

        self.is_testing_running = True
        self.update_status_signal.emit("‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        logger.info(f"–ù–∞—á–∞–ª–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –§–∞–π–ª: {file_path}, –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥: {time_step}, –ø–æ—Ä–æ–≥: {threshold}")

        try:
            scaled_data, _ = self.load_and_preprocess_data(file_path, self.scaler, fit_scaler=False)
            logger.info(f"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ñ–∞–π–ª–µ: {len(scaled_data)}")

            X_new = self.create_dataset(scaled_data, time_step)
            logger.info(f"–°–æ–∑–¥–∞–Ω–æ {X_new.shape[0]} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")

            if X_new.size == 0:
                raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω. –£–º–µ–Ω—å—à–∏—Ç–µ '–í—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥'.")

            X_new = X_new.reshape(X_new.shape[0], time_step, scaled_data.shape[1])

            self.update_status_signal.emit("üîç –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            reconstruction_errors = np.mean(np.power(X_new - self.autoencoder.predict(X_new, verbose=0), 2),
                                            axis=(1, 2))
            anomalies = np.where(reconstruction_errors > threshold)[0]
            logger.info(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π.")

            results = {
                'reconstruction_errors': reconstruction_errors,
                'anomalies': anomalies
            }

            self.testing_finished.emit(results)
            self.update_status_signal.emit(f"‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π.")
        except Exception as e:
            self.update_status_signal.emit(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            logger.error("–û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—á–µ–º –ø–æ—Ç–æ–∫–µ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", exc_info=True)
        finally:
            self.is_testing_running = False

    def _log_incident(self, error, metrics):
        """
        –°–æ–∑–¥–∞–µ—Ç –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏–Ω—Ü–∏–¥–µ–Ω—Ç –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
        """
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é 'incidents', –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not os.path.exists('incidents'):
            os.makedirs('incidents')

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON-—Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
        incident = {
            "gid": None,
            "sid": None,
            "rev": None,
            "signature_msg": f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∞–Ω–æ–º–∞–ª–∏—è. –û—à–∏–±–∫–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: {error:.4f}",
            "appearance_time": datetime.now().isoformat(),
            "priority": 1,
            # –í—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–ø–æ–ª–Ω—è–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏, —Ç.–∫. —Å–∏—Å—Ç–µ–º–∞ –Ω–µ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–∞–∫–µ—Ç–∞–º
            "source_ip": "N/A",
            "source_port": "N/A",
            "destination_ip": "N/A",
            "destination_port": "N/A",
            "packet_dump": "N/A",
            "metrics": metrics
        }

        file_path = 'incidents/incidents.json'

        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ —Å –Ω–∞—á–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump([incident], f, indent=4)
        else:
            # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç—ã, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
            try:
                with open(file_path, 'r+', encoding='utf-8') as f:
                    data = json.load(f)
                    data.append(incident)
                    f.seek(0)
                    json.dump(data, f, indent=4)
                    f.truncate()
            except json.JSONDecodeError:
                # –ï—Å–ª–∏ —Ñ–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump([incident], f, indent=4)

    @QtCore.pyqtSlot(list, int, float)
    def process_online_data(self, data_list, time_step, threshold):
        if self.autoencoder is None or self.scaler is None:
            self.update_status_signal.emit("‚ùå –û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –¥–ª—è –æ–Ω–ª–∞–π–Ω-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
            return

        try:
            if not data_list:
                raise ValueError("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–æ–∫ –≤ NumPy-–º–∞—Å—Å–∏–≤
            data_array = np.array(data_list)

            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
            if data_array.shape[1] != self.scaler.n_features_in_:
                raise ValueError(
                    f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –æ–Ω–ª–∞–π–Ω-–¥–∞–Ω–Ω—ã—Ö. –û–∂–∏–¥–∞–µ—Ç—Å—è {self.scaler.n_features_in_}, –ø–æ–ª—É—á–µ–Ω–æ {data_array.shape[1]}."
                )

            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ—Ç –∂–µ scaler, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
            scaled_data = self.scaler.transform(data_array)

            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            X_new = scaled_data.reshape(1, time_step, scaled_data.shape[1])

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            reconstruction_errors = np.mean(np.power(X_new - self.autoencoder.predict(X_new, verbose=0), 2),
                                            axis=(1, 2))
            is_anomaly = reconstruction_errors[0] > threshold

            results = {
                'error': reconstruction_errors[0],
                'is_anomaly': is_anomaly
            }
            self.online_results_signal.emit(results)

            # --- –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê –î–õ–Ø –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–û–ì–û –ü–û–î–•–û–î–ê ---
            # –ï—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∞–Ω–æ–º–∞–ª–∏—è, –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –µ–µ –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
            if is_anomaly:
                self._log_incident(results['error'], data_list)
                self.update_status_signal.emit("üìù –ò–Ω—Ü–∏–¥–µ–Ω—Ç –∑–∞–ø–∏—Å–∞–Ω –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –∂—É—Ä–Ω–∞–ª.")
            # --- –ö–û–ù–ï–¶ –ù–û–í–û–ô –õ–û–ì–ò–ö–ò ---

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ–Ω–ª–∞–π–Ω-–¥–∞–Ω–Ω—ã—Ö: {e}", exc_info=True)
            self.update_status_signal.emit(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ–Ω–ª–∞–π–Ω-–¥–∞–Ω–Ω—ã—Ö: {e}")


# --- –ù–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–Ω–ª–∞–π–Ω-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (—Å–µ—Ç–µ–≤–æ–π —Å–æ–∫–µ—Ç) ---
class OnlineTestingWorker(QtCore.QObject):
    """
    –ö–ª–∞—Å—Å-—Ä–∞–±–æ—Ç–Ω–∏–∫ –¥–ª—è –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –ø–æ—Ä—Ç–∞ –∏ –ø—Ä–∏–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–µ—Ç–∏.
    """
    update_status_signal = QtCore.pyqtSignal(str)
    # –°–∏–≥–Ω–∞–ª –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ MLWorker
    data_received_signal = QtCore.pyqtSignal(list, int, float)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.is_running = False
        self.socket = None
        self.data_buffer = collections.deque(maxlen=1000)
        self.lock = QtCore.QMutex()

    @QtCore.pyqtSlot(int, int, float)
    def start_listening(self, port, time_step, threshold):
        if self.is_running:
            self.update_status_signal.emit("‚ö†Ô∏è –û–Ω–ª–∞–π–Ω-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            return

        self.is_running = True
        self.time_step = time_step
        self.threshold = threshold

        self.update_status_signal.emit(f"‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –ø—Ä–∏–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ø–æ—Ä—Ç—É: {port}...")

        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.settimeout(1.0)

        try:
            self.socket.bind(('127.0.0.1', port))
            self.socket.listen(1)
            self.update_status_signal.emit(f"‚úÖ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω, –æ–∂–∏–¥–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –æ—Ç —Å–Ω–∏—Ñ—Ñ–µ—Ä–∞...")

            conn, addr = self.socket.accept()
            with conn:
                self.update_status_signal.emit(f"üîó –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∫–ª–∏–µ–Ω—Ç–æ–º: {addr}")
                buffer = b''
                while self.is_running:
                    data = conn.recv(4096)
                    if not data:
                        self.update_status_signal.emit(f"–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ –∫–ª–∏–µ–Ω—Ç–æ–º: {addr}")
                        break

                    buffer += data
                    # –ü–æ–ø—ã—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ.
                    try:
                        decoded_data = buffer.decode('utf-8')
                        data_list = json.loads(decoded_data)

                        if not isinstance(data_list, list):
                            self.update_status_signal.emit("‚ùå –ü–æ–ª—É—á–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: –æ–∂–∏–¥–∞–ª—Å—è —Å–ø–∏—Å–æ–∫.")
                            buffer = b''
                            continue

                        self.lock.lock()
                        try:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º append(), —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ü–µ–ª–∏–∫–æ–º
                            self.data_buffer.append(data_list)

                            if len(self.data_buffer) >= self.time_step:
                                window = list(self.data_buffer)[-self.time_step:]
                                self.data_received_signal.emit(window, self.time_step, self.threshold)
                        finally:
                            self.lock.unlock()

                        buffer = b''

                    except json.JSONDecodeError:
                        continue
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}", exc_info=True)
                        self.update_status_signal.emit(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
                        buffer = b''

        except socket.timeout:
            if self.is_running:
                QtCore.QTimer.singleShot(100, lambda: self.start_listening(port, time_step,
                                                                           threshold))
        except Exception as e:
            self.update_status_signal.emit(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–µ—Ä–∞: {e}")
            logger.critical("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–æ–∫–µ—Ç-—Å–µ—Ä–≤–µ—Ä", exc_info=True)
        finally:
            self.stop_listening()

    @QtCore.pyqtSlot()
    def stop_listening(self):
        if self.is_running:
            self.is_running = False
            self.update_status_signal.emit("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞...")
            if self.socket:
                self.socket.close()
                self.socket = None
                self.update_status_signal.emit("‚úÖ –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")