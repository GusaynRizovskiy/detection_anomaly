# -*- coding: utf-8 -*-
import os
import sys
import pandas as pd
import numpy as np
from PyQt5 import QtCore
import logging
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, LSTM, RepeatVector
from sklearn.preprocessing import MinMaxScaler
import pickle
from tensorflow.keras.callbacks import Callback

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –≤ –≥–ª–∞–≤–Ω–æ–º –º–æ–¥—É–ª–µ, –∑–¥–µ—Å—å –ø—Ä–æ—Å—Ç–æ –ø–æ–ª—É—á–∞–µ–º –ª–æ–≥–≥–µ—Ä
logger = logging.getLogger(__name__)


class PlotCallback(Callback):
    """
    –ö–ª–∞—Å—Å –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ loss –Ω–∞ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–µ.
    """

    def __init__(self, signal):
        super().__init__()
        self.signal = signal

    def on_epoch_end(self, epoch, logs=None):
        loss = logs.get('loss')
        val_loss = logs.get('val_loss')
        if loss is not None and val_loss is not None:
            self.signal.emit({'epoch': epoch, 'loss': loss, 'val_loss': val_loss})


class Worker(QtCore.QObject):
    """
    –ö–ª–∞—Å—Å-—Ä–∞–±–æ—Ç–Ω–∏–∫ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–µ–º–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ.
    –ù–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç QObject –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤.
    """

    learning_finished = QtCore.pyqtSignal(dict)
    testing_finished = QtCore.pyqtSignal(dict)
    update_status_signal = QtCore.pyqtSignal(str)
    update_plot_signal = QtCore.pyqtSignal(dict)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.autoencoder = None
        self.scaler = None
        self.is_learning_running = False
        self.is_testing_running = False
        self.epoch_data = {'loss': [], 'val_loss': []}

    def load_and_preprocess_data(self, file_path, scaler, fit_scaler=True):
        """–ó–∞–≥—Ä—É–∑–∫–∞, –æ—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π."""
        if not file_path:
            logger.error("–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –Ω–µ —É–∫–∞–∑–∞–Ω.")
            raise ValueError("–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –Ω–µ —É–∫–∞–∑–∞–Ω.")

        data = None
        delimiters = [';', ',', '\t']
        encodings = ['utf-8', 'cp1251']

        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞: {file_path}")
        # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        for delimiter in delimiters:
            for encoding in encodings:
                try:
                    data = pd.read_csv(file_path, delimiter=delimiter, encoding=encoding)
                    if data.shape[1] > 1:
                        self.update_status_signal.emit(
                            f"‚úÖ –§–∞–π–ª '{os.path.basename(file_path)}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{delimiter}' –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π '{encoding}'.")
                        logger.info(f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω. –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: {delimiter}, –ö–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding}")
                        break
                except Exception as e:
                    logger.warning(
                        f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{delimiter}' –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π '{encoding}': {e}")
                    data = None
            if data is not None and data.shape[1] > 1:
                break

        if data is None or data.shape[1] <= 1:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –∏–ª–∏ –æ–Ω –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç–æ–ª–±—Ü–æ–≤.")
            raise ValueError(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª CSV –Ω–µ –ø—É—Å—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª–µ–µ –æ–¥–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ (';', ',', '\\t').")

        data.columns = data.columns.str.strip()
        self.update_status_signal.emit(f"üìù –°—Ç–æ–ª–±—Ü—ã –≤ —Ñ–∞–π–ª–µ: {', '.join(data.columns)}")

        if data.empty:
            logger.error("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π CSV-—Ñ–∞–π–ª –ø—É—Å—Ç –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏.")
            raise ValueError("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π CSV-—Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö.")

        if '–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤' in data.columns:
            data.drop(columns=['–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤'], inplace=True)
            self.update_status_signal.emit("üóëÔ∏è –°—Ç–æ–ª–±–µ—Ü '–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤' —É–¥–∞–ª–µ–Ω.")

        data = data.replace(',', '.', regex=True)
        data = data.apply(pd.to_numeric, errors='coerce')
        self.update_status_signal.emit(f"üî¢ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ {data.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç.")

        rows_before = len(data)
        data = data.dropna()
        rows_after = len(data)
        if rows_before - rows_after > 0:
            self.update_status_signal.emit(f"‚ùå –£–¥–∞–ª–µ–Ω–æ {rows_before - rows_after} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.")
            logger.warning(f"–£–¥–∞–ª–µ–Ω–æ {rows_before - rows_after} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.")

        if data.empty:
            logger.error("–í DataFrame –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.")
            raise ValueError("–í DataFrame –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª–µ.")

        if fit_scaler or scaler is None:
            new_scaler = MinMaxScaler()
            scaled_data = new_scaler.fit_transform(data)
            self.update_status_signal.emit("üìä –î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã –Ω–æ–≤—ã–º MinMaxScaler.")
            logger.info("–î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã –Ω–æ–≤—ã–º MinMaxScaler.")
            return scaled_data, new_scaler
        else:
            scaled_data = scaler.transform(data)
            self.update_status_signal.emit("üìä –î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º MinMaxScaler.")
            logger.info("–î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º MinMaxScaler.")
            return scaled_data, scaler

    def create_dataset(self, data, time_step):
        X = []
        for i in range(len(data) - time_step):
            a = data[i:(i + time_step), :]
            X.append(a)
        return np.array(X)

    def build_cnn_lstm_autoencoder(self, input_shape):
        input_layer = Input(shape=input_shape)
        conv_encoder = Conv1D(32, kernel_size=3, activation='relu', padding='same')(input_layer)
        lstm_encoder = LSTM(50, activation='relu', return_sequences=False)(conv_encoder)
        repeat = RepeatVector(input_shape[0])(lstm_encoder)
        lstm_decoder = LSTM(50, activation='relu', return_sequences=True)(repeat)
        conv_decoder = Conv1D(32, kernel_size=3, activation='relu', padding='same')(lstm_decoder)
        output_layer = Conv1D(input_shape[1], kernel_size=3, padding='same')(conv_decoder)
        model = Model(inputs=input_layer, outputs=output_layer)
        model.compile(optimizer='adam', loss='mse')
        return model

    @QtCore.pyqtSlot(str, int, int, int)
    def start_learning(self, file_path, time_step, epochs, batch_size):
        if self.is_learning_running:
            self.update_status_signal.emit("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è.")
            return

        self.is_learning_running = True
        self.update_status_signal.emit("‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        logger.info(
            f"–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è. –§–∞–π–ª: {file_path}, –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥: {time_step}, —ç–ø–æ—Ö–∏: {epochs}, –±–∞—Ç—á: {batch_size}")

        try:
            scaled_data, self.scaler = self.load_and_preprocess_data(file_path, self.scaler, fit_scaler=True)
            X_train = self.create_dataset(scaled_data, time_step)

            logger.info(f"–°–æ–∑–¥–∞–Ω–æ {X_train.shape[0]} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")

            if X_train.size == 0:
                raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω. –£–º–µ–Ω—å—à–∏—Ç–µ '–í—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥'.")

            X_train = X_train.reshape(X_train.shape[0], time_step, scaled_data.shape[1])
            self.autoencoder = self.build_cnn_lstm_autoencoder((X_train.shape[1], X_train.shape[2]))

            plot_callback = PlotCallback(self.update_plot_signal)

            history = self.autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, validation_split=0.2,
                                           verbose=0, callbacks=[plot_callback])
            logger.info("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")

            self.update_status_signal.emit("üß† –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞. –†–∞—Å—á–µ—Ç –ø–æ—Ä–æ–≥–∞ –∞–Ω–æ–º–∞–ª–∏–π...")

            reconstruction_errors = np.mean(np.power(X_train - self.autoencoder.predict(X_train, verbose=0), 2),
                                            axis=(1, 2))
            threshold = np.percentile(reconstruction_errors, 95)
            logger.info(f"–†–∞—Å—Å—á–∏—Ç–∞–Ω –ø–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª–∏–π: {threshold:.4f}")

            results = {
                'threshold': threshold
            }

            self.learning_finished.emit(results)
            self.update_status_signal.emit("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        except Exception as e:
            self.update_status_signal.emit(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}")
            logger.error("–û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—á–µ–º –ø–æ—Ç–æ–∫–µ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è", exc_info=True)
        finally:
            self.is_learning_running = False

    @QtCore.pyqtSlot(str, int, float)
    def start_testing(self, file_path, time_step, threshold):
        if self.is_testing_running:
            self.update_status_signal.emit("‚ö†Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
            return
        if self.autoencoder is None or self.scaler is None:
            self.update_status_signal.emit("‚ö†Ô∏è –û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            logger.error("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ: –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            return

        self.is_testing_running = True
        self.update_status_signal.emit("‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        logger.info(f"–ù–∞—á–∞–ª–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –§–∞–π–ª: {file_path}, –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥: {time_step}, –ø–æ—Ä–æ–≥: {threshold}")

        try:
            scaled_data, _ = self.load_and_preprocess_data(file_path, self.scaler, fit_scaler=False)
            logger.info(f"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ñ–∞–π–ª–µ: {len(scaled_data)}")

            X_new = self.create_dataset(scaled_data, time_step)
            logger.info(f"–°–æ–∑–¥–∞–Ω–æ {X_new.shape[0]} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")

            if X_new.size == 0:
                raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω. –£–º–µ–Ω—å—à–∏—Ç–µ '–í—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥'.")

            X_new = X_new.reshape(X_new.shape[0], time_step, scaled_data.shape[1])

            self.update_status_signal.emit("üîç –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            reconstruction_errors = np.mean(np.power(X_new - self.autoencoder.predict(X_new, verbose=0), 2),
                                            axis=(1, 2))
            anomalies = np.where(reconstruction_errors > threshold)[0]
            logger.info(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π.")

            results = {
                'reconstruction_errors': reconstruction_errors,
                'anomalies': anomalies
            }

            self.testing_finished.emit(results)
            self.update_status_signal.emit(f"‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π.")
        except Exception as e:
            self.update_status_signal.emit(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            logger.error("–û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—á–µ–º –ø–æ—Ç–æ–∫–µ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", exc_info=True)
        finally:
            self.is_testing_running = False

    def stop(self):
        pass