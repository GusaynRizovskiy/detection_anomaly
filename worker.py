# -*- coding: utf-8 -*-
import os
import sys
import pandas as pd
import numpy as np
from PyQt5 import QtCore
import logging
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, LSTM, RepeatVector
from sklearn.preprocessing import MinMaxScaler
import pickle

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—á–µ–≥–æ –ø–æ—Ç–æ–∫–∞
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class Worker(QtCore.QObject):
    """
    –ö–ª–∞—Å—Å-—Ä–∞–±–æ—Ç–Ω–∏–∫ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–µ–º–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ.
    –ù–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç QObject –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤.
    """

    # –°–∏–≥–Ω–∞–ª—ã –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å –æ—Å–Ω–æ–≤–Ω—ã–º –ø–æ—Ç–æ–∫–æ–º GUI
    learning_finished = QtCore.pyqtSignal(dict)  # –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
    testing_finished = QtCore.pyqtSignal(dict)  # –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    update_status_signal = QtCore.pyqtSignal(str)  # –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Å—Ç–∞—Ç—É—Å–Ω–æ–π —Å—Ç—Ä–æ–∫–∏

    def __init__(self, parent=None):
        super().__init__(parent)
        self.autoencoder = None
        self.scaler = None
        self.is_learning_running = False
        self.is_testing_running = False

    def load_and_preprocess_data(self, file_path, scaler, fit_scaler=True):
        """–ó–∞–≥—Ä—É–∑–∫–∞, –æ—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏."""
        if not file_path:
            raise ValueError("–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –Ω–µ —É–∫–∞–∑–∞–Ω.")

        try:
            # 1. –ü–æ–ø—ã—Ç–∫–∞ —á—Ç–µ–Ω–∏—è –≤ –∫–æ–¥–∏—Ä–æ–≤–∫–µ utf-8
            data = pd.read_csv(file_path, delimiter=';', encoding='utf-8')
        except UnicodeDecodeError:
            try:
                # 2. –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏, –ø—Ä–æ–±—É–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É cp1251
                data = pd.read_csv(file_path, delimiter=';', encoding='cp1251')
            except UnicodeDecodeError:
                # 3. –ï—Å–ª–∏ –∏ —ç—Ç–æ –Ω–µ –ø–æ–º–æ–≥–ª–æ, –≤—ã–≤–æ–¥–∏–º –æ—à–∏–±–∫—É
                raise ValueError(
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –µ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ UTF-8 –∏–ª–∏ CP1251.")

        self.update_status_signal.emit(f"‚úÖ –§–∞–π–ª '{os.path.basename(file_path)}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")

        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
        data.columns = data.columns.str.strip()
        self.update_status_signal.emit(f"üìù –°—Ç–æ–ª–±—Ü—ã –≤ —Ñ–∞–π–ª–µ: {', '.join(data.columns)}")

        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ DataFrame –Ω–µ –ø—É—Å—Ç–æ–π –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
        if data.empty:
            raise ValueError("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π CSV-—Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö.")

        # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ —Å –≤—Ä–µ–º–µ–Ω–µ–º, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if '–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤' in data.columns:
            data.drop(columns=['–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤'], inplace=True)
            self.update_status_signal.emit("üóëÔ∏è –°—Ç–æ–ª–±–µ—Ü '–í—Ä–µ–º—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–∞–∫–µ—Ç–æ–≤' —É–¥–∞–ª–µ–Ω.")

        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
        data = data.replace(',', '.', regex=True)
        data = data.apply(pd.to_numeric, errors='coerce')
        self.update_status_signal.emit(f"üî¢ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ {data.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç.")

        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        rows_before = len(data)
        data = data.dropna()
        rows_after = len(data)
        if rows_before - rows_after > 0:
            self.update_status_signal.emit(f"‚ùå –£–¥–∞–ª–µ–Ω–æ {rows_before - rows_after} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.")

        # !!! –ì–õ–ê–í–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–†–û–í–ï–†–ö–ê –ü–£–°–¢–û–ì–û DATAFRAME !!!
        if data.empty:
            raise ValueError("–í DataFrame –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª–µ.")

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if fit_scaler or scaler is None:
            new_scaler = MinMaxScaler()
            scaled_data = new_scaler.fit_transform(data)
            self.update_status_signal.emit("üìä –î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã –Ω–æ–≤—ã–º MinMaxScaler.")
            return scaled_data, new_scaler
        else:
            scaled_data = scaler.transform(data)
            self.update_status_signal.emit("üìä –î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º MinMaxScaler.")
            return scaled_data, scaler

    def create_dataset(self, data, time_step):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤."""
        X = []
        for i in range(len(data) - time_step):
            a = data[i:(i + time_step), :]
            X.append(a)
        return np.array(X)

    def build_cnn_lstm_autoencoder(self, input_shape):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞."""
        input_layer = Input(shape=input_shape)
        conv_encoder = Conv1D(32, kernel_size=3, activation='relu', padding='same')(input_layer)
        lstm_encoder = LSTM(50, activation='relu', return_sequences=False)(conv_encoder)
        repeat = RepeatVector(input_shape[0])(lstm_encoder)
        lstm_decoder = LSTM(50, activation='relu', return_sequences=True)(repeat)
        conv_decoder = Conv1D(32, kernel_size=3, activation='relu', padding='same')(lstm_decoder)
        output_layer = Conv1D(input_shape[1], kernel_size=3, padding='same')(conv_decoder)
        model = Model(inputs=input_layer, outputs=output_layer)
        model.compile(optimizer='adam', loss='mse')
        return model

    @QtCore.pyqtSlot(str, int, int, int)
    def start_learning(self, file_path, time_step, epochs, batch_size):
        """–°–ª–æ—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."""
        if self.is_learning_running:
            self.update_status_signal.emit("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            return

        self.is_learning_running = True
        self.update_status_signal.emit("‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        try:
            scaled_data, self.scaler = self.load_and_preprocess_data(file_path, self.scaler, fit_scaler=True)
            X_train = self.create_dataset(scaled_data, time_step)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ X_train –Ω–µ –ø—É—Å—Ç–æ–π
            if X_train.size == 0:
                raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω. –£–º–µ–Ω—å—à–∏—Ç–µ '–í—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥'.")

            X_train = X_train.reshape(X_train.shape[0], time_step, scaled_data.shape[1])
            self.autoencoder = self.build_cnn_lstm_autoencoder((X_train.shape[1], X_train.shape[2]))

            history = self.autoencoder.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, validation_split=0.2,
                                           verbose=0)
            self.update_status_signal.emit("üß† –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞. –†–∞—Å—á–µ—Ç –ø–æ—Ä–æ–≥–∞ –∞–Ω–æ–º–∞–ª–∏–π...")

            reconstruction_errors = np.mean(np.power(X_train - self.autoencoder.predict(X_train, verbose=0), 2),
                                            axis=(1, 2))
            threshold = np.percentile(reconstruction_errors, 95)

            results = {
                'loss': history.history['loss'],
                'val_loss': history.history['val_loss'],
                'threshold': threshold
            }

            self.learning_finished.emit(results)
            self.update_status_signal.emit("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        except Exception as e:
            self.update_status_signal.emit(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}")
            logging.error("–û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—á–µ–º –ø–æ—Ç–æ–∫–µ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è", exc_info=True)
        finally:
            self.is_learning_running = False

    @QtCore.pyqtSlot(str, int, float)
    def start_testing(self, file_path, time_step, threshold):
        """–°–ª–æ—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏."""
        if self.is_testing_running:
            self.update_status_signal.emit("‚ö†Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ.")
            return
        if self.autoencoder is None or self.scaler is None:
            self.update_status_signal.emit("‚ö†Ô∏è –û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            return

        self.is_testing_running = True
        self.update_status_signal.emit("‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        try:
            scaled_data, _ = self.load_and_preprocess_data(file_path, self.scaler, fit_scaler=False)
            X_new = self.create_dataset(scaled_data, time_step)

            if X_new.size == 0:
                raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω. –£–º–µ–Ω—å—à–∏—Ç–µ '–í—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥'.")

            X_new = X_new.reshape(X_new.shape[0], time_step, scaled_data.shape[1])

            self.update_status_signal.emit("üîç –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            reconstruction_errors = np.mean(np.power(X_new - self.autoencoder.predict(X_new, verbose=0), 2),
                                            axis=(1, 2))
            anomalies = np.where(reconstruction_errors > threshold)[0]

            results = {
                'reconstruction_errors': reconstruction_errors,
                'anomalies': anomalies
            }

            self.testing_finished.emit(results)
            self.update_status_signal.emit(f"‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π.")
        except Exception as e:
            self.update_status_signal.emit(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            logging.error("–û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—á–µ–º –ø–æ—Ç–æ–∫–µ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", exc_info=True)
        finally:
            self.is_testing_running = False

    def stop(self):
        """–ú–µ—Ç–æ–¥ –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—Ç–æ–∫–∞, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ."""
        pass